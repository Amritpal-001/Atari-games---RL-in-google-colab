# Reinforcement learning - Projects

AIM - 
1. Run openAI gym in Jupyter notebook(google colab), with virtual screen
2. Basic Neural networks for learning

## Jupyter notebooks 

### 0. First env - Cartpole.ipynb
Working with OPenAI environments in google colab, with a virtual display   
### 1. Looking into all environments.ipynb
Exploring different environments of OpenAI

## Folder contents - 
Day 10 - Cartpole and Mountain car
Day 22 - RL aglorithms
Day 23 - Pacman
Day 24 - Atari games -  AirRaid,SpaceInvaders, Breakout
Day 25 - Robotic arm
Day 26 - Mujuco
Day 27 - GymGo


<img src="Images/Pacman.gif" alt="Fetch Slide"/> <img src="Images/SpaceInvaders.gif" alt="Pendulum"/> <img src="Images/Breakout-untrained.gif" alt="Doom Deathmatch"/>  
<br>


![Breakout](Images/Pacman.gif)

![Breakout](Images/SpaceInvaders.gif)

![Breakout - Before Training](Images/Breakout-untrained.gif)


### Opengym_MiniGrid.ipynb

<img src="Images/MiniGrid-KeyCorridorS6R3-v0-randomevents.gif" alt="Fetch Slide"/> <img src="Images/MiniGrid-LavaGapS7-v0-randomevents.gif" alt="Pendulum"/>  width = "164" height ="200" alt="Starcraft"/>
<br>
<img src="Images/MiniGrid-Dynamic-Obstacles-16x16-v0-randomevents.gif" alt="Doom Deathmatch"/> width = "164" height ="200"/>
<br><br>


### Opengym_rubiks_cube_gym_env.ipynb

![rubiks_cube_gym - Before Training](Images/rubic_cube01.png)
